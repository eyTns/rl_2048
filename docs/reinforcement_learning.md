# Reinforcement Learning Study Notes

## 원칙
- 문서 항목에 괄호, 덧붙임, 화살표 등을 사용하기 전에 해당 내용이 꼭 필요한지, 다른 맥락에서 이미 표시되었는지 검토한다

## Claude Code 세션 관리법
1. 새로운 세션을 연다
2. 베이스로 할 브랜치를 선택한다
3. 무엇을 구현하려는지 주제를 이야기한다
4. 클로드코드가 새 브랜치를 생성한다
5. 브랜치가 잘 연결되어 있는지 파악한다
6. 구현을 한다

## 기본 개념
- **State (상태)**: 현재 환경의 상황 (2048에서는 4x4 보드의 16개 숫자)
- **Action (행동)**: 에이전트가 취할 수 있는 선택 (2048에서는 상/하/좌/우)
- **Reward (보상)**: 행동에 대한 피드백, 설계가 중요함 (단순 점수보다 빈칸 수, 합쳐짐 등 고려)
- **Policy (정책)**: "이 상태에서 어떤 행동을 할까"에 대한 매핑표, RL의 목표는 최적의 Policy를 찾는 것

## 알고리즘 관계
- **RL (Reinforcement Learning)**: 강화학습 전체를 아우르는 큰 분야
- **Q-Learning**: RL의 한 알고리즘, Q-table에 (상태, 행동)별 가치를 저장
- **Deep Q-Learning (DQN)**: Q-table 대신 신경망 사용, 상태가 많을 때 필수 (2048은 상태가 무수히 많으므로 DQN 필요)

## 알아볼 내용
- [ ] 학습이 어떤 계산식으로 이루어지는지 (Q-Learning 수식)
- [x] Q-Learning과 Deep Q-Learning과 RL의 차이
- [ ] Policy가 구체적으로 어떻게 구현되는지
- [x] DQN은 구체적으로 어떤 방식으로 동작하는지
- [ ] Policy와 Reward의 관계
- [ ] Q값을 정규화(normalize) 하는가?
- [ ] 머신러닝 시스템 설계 방법
- [ ] DQN의 레이어 구성
- [ ] 차원수와 모델 용량
- [ ] 회전/대칭 상태를 동일하게 처리하는 테크닉
- [ ] 학습 과정 시각화
- [ ] 2048 구현 PR 검토하기
- [ ] 게임 시각화
- [x] 게임 플레이 UI 생성
- [ ] 게임 플레이 UI PR 검토하기
- [ ] 머신러닝 장면 시각화
- [x] PR이 있을 때 추가 작업 시 브랜치 관리 방법
- [ ] Delayed Reward 개념 확인
- [ ] Discount Factor 개념 확인
- [ ] 시스템, 모듈설계
- [ ] 모듈과 레이어 정의하기

