# Conv Branch 아키텍처 전환 검토 보고서

## 1. 현행 아키텍처 vs 제안 아키텍처 비교

### 현행 (Fully Connected 3-Layer)

```
Input: (4,4) board → one-hot flatten → 256-dim vector
  ↓
Dense 1: 256 → 256, ReLU
  ↓
Dense 2: 256 → 256, ReLU
  ↓
Output:  256 → 4, Linear
```

| 레이어 | 가중치 | 바이어스 | 소계 |
|--------|--------|---------|------|
| Dense 1 (256→256) | 65,536 | 256 | 65,792 |
| Dense 2 (256→256) | 65,536 | 256 | 65,792 |
| Output (256→4) | 1,024 | 4 | 1,028 |
| **합계** | | | **132,612** |

### 제안 (Conv Branch + FC)

```
Input: (4,4,16) one-hot encoding
  ├─ Branch A: Conv2D(16, kernel=(1,2), padding='same') → (4,4,16)  [수평]
  └─ Branch B: Conv2D(16, kernel=(2,1), padding='same') → (4,4,16)  [수직]
  ↓ Concatenate
(4,4,32) → Flatten → 512
  ↓
Dense 1: 512 → 64, ReLU
  ↓
Dense 2: 64 → 32, ReLU
  ↓
Output:  32 → 4, Linear
```

| 레이어 | 가중치 | 바이어스 | 소계 |
|--------|--------|---------|------|
| Branch A Conv2D (1×2×16→16) | 512 | 16 | 528 |
| Branch B Conv2D (2×1×16→16) | 512 | 16 | 528 |
| Dense 1 (512→64) | 32,768 | 64 | 32,832 |
| Dense 2 (64→32) | 2,048 | 32 | 2,080 |
| Output (32→4) | 128 | 4 | 132 |
| **합계** | | | **36,100** |

**파라미터 비율: 제안/현행 = 36,100 / 132,612 ≈ 27.2% (약 3.7배 감소)**

---

## 2. 장점 분석

### 2.1 공간 구조 보존 (가장 큰 개선점)

현행 모델의 근본적 한계는 입력 단계에서 4×4 보드를 256차원 벡터로 **즉시 평탄화(flatten)** 한다는 점이다. 이로 인해 "셀 (0,0)과 셀 (0,1)은 가로로 인접해 있다"는 공간 정보가 완전히 소실되며, Dense 레이어가 이 관계를 처음부터 학습해야 한다.

제안 모델은 Conv2D를 통해 **공간적 인접성을 구조적으로 인코딩**하므로, 네트워크가 "인접 타일 간 관계"를 사전지식(inductive bias)으로 갖게 된다.

### 2.2 방향별 분해의 게임 적합성

2048의 핵심 메커닉은 **행 또는 열 방향 병합**이다:
- Branch A `(1,2)` 커널: 수평 인접 쌍 `[a, b]` 패턴 감지 → 좌/우 이동 판단에 직결
- Branch B `(2,1)` 커널: 수직 인접 쌍 `[a; b]` 패턴 감지 → 상/하 이동 판단에 직결

이 분해는 게임의 행동 공간(상/하/좌/우)과 구조적으로 정렬되어 있어, 각 branch가 자연스럽게 해당 방향의 병합 가능성을 학습할 수 있다.

### 2.3 파라미터 효율성

132K → 36K로 약 73% 감소. 2048의 상태 공간은 이론적으로 크지만, 실제 학습에서 마주치는 유효 상태 분포는 제한적이다. 작은 모델은:
- 에피소드당 학습 속도 향상 (역전파 연산량 감소)
- 과적합 위험 감소
- 학습 초기 수렴 가능성 향상

---

## 3. 우려 사항 및 약점

### 3.1 수용 영역(Receptive Field) 부족 — 심각도: 높음

`(1,2)` 커널은 수평으로 **2셀만** 관찰한다. 2048에서 고급 전략은 **행/열 전체(4셀)**에 걸친 패턴 인식을 요구한다:

```
전략적으로 중요한 패턴 예시:
[256, 128, 64, 32]  ← 단조 감소 행 (코너 전략의 핵심)
[  2,   2,  4,  4]  ← 연쇄 병합 가능 (2+2→4, 4+4→8)
```

단일 `(1,2)` 커널로는 `[256, 128]`, `[128, 64]`, `[64, 32]` 각 쌍만 독립적으로 볼 수 있고, **행 전체의 단조성**이나 **연쇄 병합 가능성**을 직접 인식할 수 없다. 이 정보는 이후 Dense 레이어가 재조합해야 하지만, 512→64 병목으로 인해 복원이 어렵다.

### 3.2 Dense 레이어 병목 — 심각도: 높음

```
현행: 256 → 256 → 256 → 4   (표현력 유지)
제안: 512 → 64  → 32  → 4   (급격한 축소)
```

512→64 전환에서 정보의 **87.5%가 한 번에 압축**된다. Conv 레이어의 출력인 (4,4,32) = 512차원은 각 위치의 수평/수직 패턴 정보를 담고 있는데, 이를 64차원으로 축소하면 세밀한 위치별 정보가 크게 손실될 수 있다.

특히 2048은 **같은 타일 값이라도 위치에 따라 가치가 완전히 다른** 게임이다:
- 코너의 512와 중앙의 512는 전략적 가치가 다르다
- 이 위치 의존적 가치 판단에 64개 노드가 충분한지 의문

### 3.3 Conv 레이어 활성화 함수 미명시 — 심각도: 중간

제안에서 Conv2D 레이어의 활성화 함수가 명시되지 않았다. 만약 활성화 없이(linear) 사용한다면, Conv 연산은 단순한 **선형 필터**에 불과하며 XOR 같은 비선형 패턴을 학습할 수 없다.

예: "이 두 셀이 같은 값인가?" = `(a == b)`는 비선형 판단이므로, 활성화 함수(ReLU) 없이는 Conv 레이어가 이를 직접 표현할 수 없다.

### 3.4 NumPy 순수 구현의 복잡도 — 심각도: 높음 (구현 관점)

현행 코드베이스는 **순수 NumPy**로 forward/backward를 구현한다. Conv2D의 역전파를 NumPy로 구현하려면:

1. **im2col 변환**: 입력 텐서를 컨볼루션 연산에 맞게 재배열
2. **padding 처리**: 'same' 패딩의 정확한 구현
3. **gradient 계산**: `dW`, `db`, `dX` 각각에 대한 미분
4. **col2im 역변환**: 그래디언트를 원래 텐서 형태로 복원
5. **Concatenate 역전파**: 그래디언트를 두 branch로 분할

현행 Dense 레이어의 역전파(`model.py:119-151`)는 단순 행렬곱 체인이지만, Conv2D 역전파는 이보다 **구현 복잡도가 5~10배** 높다. 버그 발생 확률이 크게 증가하며, 디버깅도 어렵다.

### 3.5 단일 Conv 레이어의 한계 — 심각도: 중간

각 branch가 Conv 1개만 사용하므로 추출 가능한 특징이 **저수준(low-level)**에 머문다:
- 학습 가능: "인접한 두 셀이 비슷한 값인가?"
- 학습 불가: "이 행이 단조 감소 패턴인가?", "코너에 가장 큰 값이 있는가?"

이러한 고수준 패턴은 Conv 레이어를 여러 겹 쌓거나, Dense 레이어에서 충분한 용량으로 학습해야 하는데, 제안의 Dense 용량(64→32)이 이를 감당하기엔 부족할 수 있다.

---

## 4. 정량적 영향 예측

| 지표 | 현행 (FC 3-Layer) | 제안 (Conv Branch) | 예측 근거 |
|------|-------------------|-------------------|----------|
| 에피소드당 연산량 | 기준 | ~40-60% (파라미터 감소) | 36K vs 132K params |
| 에피소드당 학습 시간 | 기준 | ~50-70% (Conv 오버헤드 일부 상쇄) | im2col 추가 비용 |
| 초기 수렴 속도 | 기준 | 개선 가능 | Conv의 inductive bias |
| 최종 도달 점수 | 기준 | 하락 우려 | 수용영역 부족 + 병목 |
| 최대 타일 달성률 (2048) | 기준 | 하락 우려 | 고수준 전략 학습 한계 |
| 구현 난이도 | 낮음 | 매우 높음 | NumPy Conv2D 역전파 |

---

## 5. 개선 권고안

제안 아키텍처의 핵심 아이디어(방향별 Conv 분해)는 유효하지만, 실효성을 높이려면 다음 조정이 필요하다:

### 5.1 수용 영역 확대

```
# 방안 A: 커널 크기 확대 (1,4) / (4,1) — 행/열 전체 커버
Branch A: Conv2D(16, kernel=(1,4), padding='same')  → 수평 행 전체
Branch B: Conv2D(16, kernel=(4,1), padding='same')  → 수직 열 전체

# 방안 B: Conv 2단 적층
Branch A: Conv2D(16, (1,2), 'same', ReLU) → Conv2D(16, (1,2), 'same', ReLU)
  → 수용영역: 1×3 (2단 적층으로 확장)

# 방안 C: 방안 A + B 혼합
Branch A: Conv2D(16, (1,4), 'same', ReLU) → Conv2D(16, (1,2), 'same', ReLU)
  → 수용영역: 1×5 (행 전체 이상)
```

**권고: 방안 A**가 구현 대비 효과가 가장 크다. `(1,4)` 커널은 행 전체를 한 번에 보므로 단조 감소 패턴 등을 직접 감지할 수 있다.

### 5.2 Dense 레이어 용량 확보

```
# 현 제안
Dense 1: 512 → 64   (87.5% 압축)
Dense 2: 64  → 32   (50% 압축)

# 권고안
Dense 1: 512 → 256  (50% 압축)
Dense 2: 256 → 64   (75% 압축)
```

이 경우 총 파라미터: 528 + 528 + (512×256+256) + (256×64+64) + (64×4+4) = **148,468**
현행(132,612)과 비슷한 규모이지만, Conv의 inductive bias가 추가되어 같은 파라미터 예산으로 더 나은 성능이 가능하다.

### 5.3 Conv 후 활성화 함수 추가

```
Branch A: Conv2D(16, (1,2), 'same') → ReLU → (4,4,16)
Branch B: Conv2D(16, (2,1), 'same') → ReLU → (4,4,16)
```

비선형 활성화 없이는 Conv가 단순 선형 변환에 그치며, 병합 가능 여부 같은 비선형 패턴을 학습할 수 없다.

### 5.4 (2,2) Branch 추가 고려

```
Branch C: Conv2D(16, kernel=(2,2), padding='same') → (4,4,16)
```

2048에서 2×2 블록 패턴도 중요하다 (예: 코너 전략에서 L자형 배치). 3-branch 구조는 파라미터 증가가 미미(+528)하면서 표현력을 높일 수 있다.

### 5.5 구현 전략: PyTorch/JAX 전환 권고

Conv2D의 역전파를 NumPy로 직접 구현하는 것은 비용 대비 효과가 낮다. 두 가지 대안:

1. **PyTorch 전환**: `torch.nn.Conv2d` + autograd 활용 → 역전파 자동 처리
2. **최소 Conv 구현**: forward만 NumPy로 구현하고, finite difference로 그래디언트 근사 (학습 속도 매우 느림, 비권장)

PyTorch 전환 시 기존 trainer.py의 학습 루프와 콜백 구조는 거의 그대로 유지 가능하며, `model.py`만 교체하면 된다.

---

## 6. 종합 결론

| 항목 | 평가 |
|------|------|
| **핵심 아이디어 (방향별 Conv)** | 우수 — 2048 게임 메커닉과 구조적으로 부합 |
| **현재 제안 그대로 적용** | 비권고 — 수용영역 부족, Dense 병목, 구현 복잡도 |
| **개선안 적용 시** | 권고 — 특히 5.1(커널 확대) + 5.2(Dense 확대) + 5.3(ReLU 추가) 조합 |

**제안 아키텍처의 방향성은 올바르다.** 현행 FC-only 모델이 공간 구조를 무시하는 것은 분명한 한계이며, Conv를 통한 공간적 inductive bias 도입은 학습 효율을 높일 수 있다. 그러나 현재 제안은 (1) 수용 영역이 2셀로 너무 좁고, (2) Dense 병목이 과도하며, (3) Conv 활성화 함수가 빠져 있어, 이대로 적용하면 오히려 **현행 대비 성능 하락**이 예상된다.

권고 수정안을 반영한 최종 아키텍처:

```
Input: (4,4,16) one-hot
  ├─ Branch A: Conv2D(16, (1,4), 'same', ReLU) → (4,4,16)   [행 전체]
  ├─ Branch B: Conv2D(16, (4,1), 'same', ReLU) → (4,4,16)   [열 전체]
  └─ Branch C: Conv2D(16, (2,2), 'same', ReLU) → (4,4,16)   [블록] (선택)
  ↓ Concatenate
(4,4,32 or 48) → Flatten → 512 or 768
  ↓
Dense 1: → 256, ReLU
  ↓
Dense 2: → 64, ReLU
  ↓
Output: → 4, Linear
```

이 구조라면 현행 모델 대비 **동일하거나 적은 파라미터**로 **더 나은 공간 인식 능력**을 확보할 수 있다.
